{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1704081831192,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"FYyvcBjmgG27"},"outputs":[],"source":["# Before proceeding run this cell (but if you have already install then ignore)\n","# !pip install tensorflow==2.15.0\n","# !pip install scikit-learn\n","# !pip install pandas\n","# !pip install numpy\n","# !pip install seaborn\n","# !pip install matplotlib\n","# !pip install wordcloud\n","# !pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1704081832967,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"S3FS41t6M4CQ"},"outputs":[],"source":["# !pip install keras-preprocessing"]},{"cell_type":"markdown","metadata":{"id":"TmrhjlqLhrz-"},"source":["#Load Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1704081832968,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"Fb2Z_94Hg4pB"},"outputs":[],"source":["\n","## dl packages\n","from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","from keras.callbacks import EarlyStopping\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","\n","# ml packages\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import nltk\n","import re\n","from nltk.stem import PorterStemmer\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# .)The WordCloud library in Python is a visualization tool used\n","# to create word clouds from a text corpus. Word clouds are\n","# graphical representations of words where the size of each\n","#  word indicates its frequency or importance within the\n","#  given text data. The more frequent a word appears in\n","#  the text, the larger and bolder it appears in the word cloud.\n","from wordcloud import WordCloud"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1704081832968,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"djWc7IQqN-Kn","outputId":"7594e5b6-e383-4949-f972-9f3f66ca50fc"},"outputs":[],"source":["# --------just for info----------\n","# .)the blw to_categorical example.\n","\n","from keras.utils import to_categorical\n","\n","# Example class labels (as integers)\n","class_labels = [0, 1, 2, 1, 0, 2]\n","\n","# Convert class labels to categorical (one-hot encoded) representation\n","one_hot_encoded = to_categorical(class_labels)\n","\n","print(one_hot_encoded)\n"]},{"cell_type":"markdown","metadata":{"id":"7HF54kinis8d"},"source":["#Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1704081832968,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"TEVlnOo9hM-J","outputId":"55f78c62-7c3d-4d92-c868-ff85400a723e"},"outputs":[],"source":["train_data = pd.read_csv(\"train.txt\", header=None, sep=\";\", names=[\"Comment\", \"Emotion\"], encoding=\"utf-8\")\n","train_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1704081832968,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"-DHM1Y9ShNA6","outputId":"a61eb77a-10c2-4713-f7f7-7c0d8370c7e8"},"outputs":[],"source":["train_data = pd.read_csv(\"train.txt\", header=None, sep=\";\", names=[\"Comment\", \"Emotion\"], encoding=\"utf-8\")\n","train_data.head()\n","# get all words length in comment\n","train_data['length'] = [len(x) for x in train_data['Comment']]\n","train_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1704081832969,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"VD2sWqgEhNGT","outputId":"07c45f44-b635-4aee-f4a6-b1175a7e31b9"},"outputs":[],"source":["train_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1704081832969,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"QsuCloebhNJT","outputId":"4e907ba0-49db-4ffd-98e4-35dfdcd3057c"},"outputs":[],"source":["train_data.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1704081832969,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"mN99ZTJChNMJ","outputId":"b22b5ae4-ed0c-40ef-edce-df9543c8b328"},"outputs":[],"source":["train_data.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1704081832969,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"FUo1Lk_ylWuw"},"outputs":[],"source":["train_data.drop_duplicates(inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"6AJw5GRdlMif"},"source":["#EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1704081832969,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"EbtXxsMPhNO_","outputId":"5c64d79d-b0fc-4589-f99d-712344693d40"},"outputs":[],"source":["sns.countplot(x = train_data['Emotion'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":1671,"status":"ok","timestamp":1704081834622,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"t4DibueRhNVG","outputId":"0582c1b8-0c99-4571-8cbc-f0114325275c"},"outputs":[],"source":["# data distribution\n","df2 = train_data.copy()\n","df2['length'] = [len(x) for x in df2['Comment']]\n","\n","# Convert the 'length' column to a numpy array\n","length_values = df2['length'].values\n","\n","# Use sns.histplot instead of sns.kdeplot for simplicity\n","sns.histplot(data=df2, x='length', hue='Emotion', multiple='stack')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vOCLwDoqjRpSqYsc1Flyx0_7-ql9SCxG"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1704081851534,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"ytEtEfrwhNbH","outputId":"75048ba2-d323-4b9f-f20e-e64eacc8f2a3"},"outputs":[],"source":["# Words colud for each emotions.\n","def words_cloud(wordcloud,emotion):\n","  plt.figure(figsize=(10,10))\n","  plt.title(emotion + \" Word Cloud\")\n","  plt.imshow(wordcloud)\n","  plt.axis(\"off\")\n","emotions_list = train_data['Emotion'].unique()\n","for emotion in emotions_list:\n","  # .)The blw loop will run for eevery unque emotions and for every\n","  # unique emotions and for that unique emotion the blw loop will\n","  # run for every comment and will be connected by \" \" and store\n","  # in text  and wordcl;oud it is passend word cloud wil find the text\n","  # words that blengs to word of emotion and remove stop words if will\n","  # create the list of words from that commments usin wordcloud.\n","  text = \" \".join([sentence for sentence in train_data.loc[train_data['Emotion']==emotion,'Comment']])\n","  wordcloud = WordCloud(width=600,height=600).generate(text)\n","  words_cloud(wordcloud,emotion)"]},{"cell_type":"markdown","metadata":{"id":"QMUYO9N0XEVe"},"source":["Data Preprocessing\n","\n","Encode emotions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1704081851534,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"8OF8dwg7hNeH","outputId":"7397c1bc-a740-45e6-a425-596014a5073c"},"outputs":[],"source":["# encoding the categorical column target column of emotions.\n","lb = LabelEncoder()\n","train_data['Emotion_Encoded'] = lb.fit_transform(train_data['Emotion'])\n","train_data"]},{"cell_type":"markdown","metadata":{"id":"XvsLNKV_X1OX"},"source":["Applying Machine Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1704081851535,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"y7vrdUE_hNg9"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score,classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1704081851535,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"6Nvh1aIvhNj2"},"outputs":[],"source":["df = train_data.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1704081851535,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"i4Y0FSrqhNmu","outputId":"852c3d6e-6021-49f2-caff-2af49e6e2d53"},"outputs":[],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"8X7fp5uIZPsX"},"source":["## Data cleaning and preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":711,"status":"ok","timestamp":1704081852211,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"GXeERL9PhNp2","outputId":"0c693684-7316-4ed2-d8cc-e3382754879d"},"outputs":[],"source":["# Download NLTK stopwords\n","nltk.download('stopwords')\n","stopwords = set(nltk.corpus.stopwords.words('english'))\n","def clean_text(text):\n","  stemmer = PorterStemmer()\n","  text = re.sub(\"[^a-zA_Z]\",\" \",text)\n","  text = text.lower()\n","  text = text.split()\n","  text = [stemmer.stem(word) for word in text if word not in stopwords]\n","\n","  return \" \".join(text)\n","\n","df['clean_comment']= df['Comment'].apply(clean_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1704081852211,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"JACsWmt2hNs_","outputId":"fba91e5b-1468-4826-c828-ed4a791b4947"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1704081852212,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"6aW6gi13hNzI"},"outputs":[],"source":["# Train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(df['clean_comment'],\n","                          df['Emotion_Encoded'],test_size=0.2,random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1704081852212,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"7_FKbKWohN2U"},"outputs":[],"source":["# Vectorization using TF-IDF\n","# .)This vectorizer will tke out the most imp words it will se the words which\n","# are repeating less no of times i single documnt and in all documnt\n","# then it formula will tke the words out whic are more imp.\n","tfidf_vectorizer = TfidfVectorizer()\n","X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n","X_test_tfidf = tfidf_vectorizer.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42970,"status":"ok","timestamp":1704081925219,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"xvpVmw1IhN5O","outputId":"58919169-163e-4c7c-9246-301a36f6ff8c"},"outputs":[],"source":["# Multi-class classification using different algorithms\n","classifiers = {\n","    \"Multinomial Naive Bayes\": MultinomialNB(),\n","    \"Logistic Regression\": LogisticRegression(),\n","    \"Random Forest\": RandomForestClassifier(),\n","    \"Support Vector Machine\": SVC(),\n","}\n","for name,clf in classifiers.items():\n","  print(f\"\\n================={name}=================\")\n","  clf.fit(X_train_tfidf,y_train)\n","  y_pred_tfidf = clf.predict(X_test_tfidf)\n","  print(f\"\\nAccuracy using TF-IDF: {accuracy_score(y_test,y_pred_tfidf)}\")\n","  print(classification_report(y_test,y_pred_tfidf))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2492,"status":"ok","timestamp":1704081927705,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"K5ZorZTbhN8C","outputId":"61308092-0f35-4f04-b675-d86c168c5a5e"},"outputs":[],"source":["# selecting model\n","lg = LogisticRegression()\n","lg.fit(X_train_tfidf, y_train)\n","lg_y_pred = lg.predict(X_test_tfidf)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":738,"status":"ok","timestamp":1704081928439,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"-U_JpoUfhN-u","outputId":"6ee4135d-60f3-48fc-c689-843807af3b23"},"outputs":[],"source":["def predict_emotion(input_text):\n","  cleaned_text = clean_text(input_text)\n","  input_vectorized = tfidf_vectorizer.transform([cleaned_text])\n","  predicted_label = lg.predict(input_vectorized)[0]\n","  predicted_emotion = lb.inverse_transform([predicted_label])[0]\n","\n","  label =  np.max(lg.predict(input_vectorized))\n","\n","  return predicted_emotion,label\n","\n","  # Example usage\n","sentences = [\n","            \"i didnt feel humiliated\",\n","            \"i feel strong and good overall\",\n","            \"im grabbing a minute to post i feel greedy wrong\",\n","            \"He was speechles when he found out he was accepted to this new job\",\n","            \"This is outrageous, how can you talk like that?\",\n","            \"I feel like im all alone in this world\",\n","            \"He is really sweet and caring\",\n","            \"You made me very crazy\",\n","            \"i am ever feeling nostalgic about the fireplace i will know that it is still on the property\",\n","            \"i am feeling grouchy\",\n","            \"He hates you\"\n","            ]\n","for sentence in sentences:\n","  print(sentence)\n","  predict_emotionn,label = predict_emotion(sentence)\n","  print(\"Predicted Emotion :\",predict_emotionn)\n","  print(\"Predicted  Label :\",label)\n","  print(\"====================================================\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1704081928439,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"2tSgaOaXhOBm"},"outputs":[],"source":["# -save files.\n","import pickle\n","pickle.dump(lg,open(\"Logistic_regression.pkl\",\"wb\"))\n","pickle.dump(lb,open(\"Label_encoder.pkl\",\"wb\"))\n","pickle.dump(tfidf_vectorizer,open(\"tfidf_vectorizer.pkl\",\"wb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1704081928440,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"ZrOiOjDZhOEf","outputId":"46a0369e-7653-4d0f-b188-9340267924dc"},"outputs":[],"source":["import sklearn\n","print(sklearn.__version__)"]},{"cell_type":"markdown","metadata":{"id":"6rjTDTfhwYFX"},"source":["#Applying Deep learning Using LSTM\n","#Text Cleaning, Ecoding, and Padding"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1704081928440,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"1uzXGCN5z7eD","outputId":"f4057934-9836-4b28-d614-34badad1df1d"},"outputs":[],"source":["max(len(w) for w in train_data['Comment'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7uLBKSG0tHq"},"outputs":[],"source":["stopwords = set(nltk.corpus.stopwords.words('english'))\n","stopwords"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1704081928440,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"rACZrgFU2oMN","outputId":"7c752440-ca2f-4295-dee3-3cdb9ee124ed"},"outputs":[],"source":["\n","text = \" \".join([\"i love myself\",'I hate you','We love ourselves'])\n","one_hot(input_text=text,n=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2831,"status":"ok","timestamp":1704081931266,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"F65TVbfyhOHR"},"outputs":[],"source":["def clean_text(df,column,vocab_size,max_len):\n","  stemmer = PorterStemmer()\n","  corpus = []\n","  for text in df[column]:\n","     \n","    text = text.lower()\n","    text = text.split()\n","    text = [stemmer.stem(w) for w in text if w not in stopwords]\n","    text = \" \".join(text)\n","    # .)Now converting the words to onehot vectors for each sentence\n","    # there will be each vector for every words.\n","    corpus.append(text)\n","  one_hot_word = [one_hot(input_text=word,n=vocab_size) for word in corpus]\n","  pad = pad_sequences(sequences=one_hot_word,maxlen= max_len,\n","                        padding='pre')\n","  return pad\n","x_train = clean_text(train_data,'Comment',vocab_size=11000,max_len=300)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1704081931267,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"s5kqXRh8-pI5","outputId":"8bdeb6c8-1487-4f08-f02c-244c659c2134"},"outputs":[],"source":["x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1704081931267,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"9fCM0HyYhONY"},"outputs":[],"source":["lb = LabelEncoder()\n","train_data['Emotion'] = lb.fit_transform(train_data['Emotion'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1704081931267,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"8ZevxiPvhOQX"},"outputs":[],"source":["# -------Using to_categorical simple info------:\n","# .)You can use the to_categorical function to convert these\n","#  categorical labels into one-hot encoded vectors:\n","\n","#  ----exmple-\n","# import numpy as np\n","# from keras.utils import to_categorical\n","\n","# # Categorical labels\n","# labels = np.array([1, 2, 0, 3, 2])\n","\n","# # Convert categorical labels to one-hot encoded vectors\n","# one_hot_labels = to_categorical(labels)\n","\n","# print(\"Original Labels:\")\n","# print(labels)\n","\n","# print(\"\\nOne-Hot Encoded Labels:\")\n","# print(one_hot_labels)\n","# # Original Labels:\n","# [1 2 0 3 2]\n","# # One-Hot Encoded Labels:\n","# [[0. 1. 0. 0.]\n","#  [0. 0. 1. 0.]\n","#  [1. 0. 0. 0.]\n","#  [0. 0. 0. 1.]\n","#  [0. 0. 1. 0.]]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUoydzQ-VhJK"},"outputs":[],"source":["y_train =to_categorical(train_data['Emotion'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":856,"status":"ok","timestamp":1704081932102,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"KCyYuRrf-xGM","outputId":"c049fc6f-f89a-4072-8ffa-ad4a8fed3ec5"},"outputs":[],"source":["y_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEfK-etE-4WG"},"outputs":[],"source":["train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1704081932103,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"dBFzdBV58a6q"},"outputs":[],"source":["# .)In deep learning, an embedding layer is a fundamental\n","# component used primarily in natural language processing\n","#  (NLP) tasks to convert categorical data, such as words\n","#   or characters, into dense vectors of fixed size.\n","#    These dense vectors, called embeddings, represent\n","#    the semantic meaning or contextual information of\n","#    the input categorical data in a continuous vector space.\n","\n","# Here's a simple explanation and an example of an embedding layer:\n","\n","# Explanation:\n","# Purpose of Embedding Layer:\n","\n","# It learns and maps each categorical input\n","#  (e.g., words from a vocabulary) to a continuous\n","#   vector space, where words with similar meanings\n","#    or contexts are closer together in this space.\n","\n","# Functionality:\n","\n","# The embedding layer is the initial layer in a neural\n","# network that performs the mapping from discrete categorical\n","# data (like words represented as integers) to continuous vector\n","#  representations (embeddings).\n","# It is typically used as the first layer in a neural\n","# network model for NLP tasks."]},{"cell_type":"markdown","metadata":{"id":"gOeeC_li6mUd"},"source":["# Model Building and Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86574,"status":"ok","timestamp":1704082018670,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"Y9M9CtSEhOTf","outputId":"ef210f5f-6c0f-4bd3-9605-1250881fcdf4"},"outputs":[],"source":["'''\n","input_dim: This parameter specifies the size of the vocabulary, i.e., the total number of unique words in your dataset. In this case, it's set to 11000, indicating that your vocabulary has 11000 unique words.\n","\n","output_dim: This parameter specifies the dimensionality of the dense embeddings. Each word in the vocabulary will be represented by a dense vector of this size. In this case, it's set to 150, meaning that each word will be represented by a 150-dimensional vector.\n","\n","input_length: This parameter specifies the length of input sequences, i.e., the number of words in each sequence. In this case, it's set to 300, indicating that your model expects input sequences with a length of 300 words.\n","\n","So, the Embedding layer in this context is creating a word embedding matrix with a vocabulary size of 11000, where each word is represented by a dense vector of 150 dimensions. The input sequences are expected to have a length of 300 words. The purpose of the Embedding layer is to learn dense representations of words in a continuous vector space, which can be further processed by other layers in your neural network.\n","'''\n","\n","model = Sequential()\n","# .)The blw embedding layer do the wor embedding. which means it\n","# converts the input sequence to dense vectors.\n","\n","model.add(Embedding(input_dim=11000,output_dim=150,input_length=300))\n","model.add(Dropout(0.2))\n","model.add(LSTM(128))\n","model.add(Dropout(0.2))\n","model.add(Dense(64,activation='sigmoid'))\n","model.add(Dropout(0.2))\n","model.add(Dense(6,activation='softmax'))\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit(x_train,y_train,epochs=5,batch_size=64,verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Ngoq116Tcqk"},"outputs":[],"source":["# .)The function sentence_cleaning appears to perform the\n","#  following steps on the input sentence:\n","\n","# 1)Removes non-alphabetic characters and converts the text to lowercase.\n","# 2)Splits the sentence into words.\n","# 3)Stems each word using the Porter Stemmer (from NLTK).\n","# 4)Removes stopwords (assuming stopwords is defined somewhere\n","#   in the code, typically a list of common words that do not\n","#               contribute much to the meaning of a sentence).\n","# 5)Joins the preprocessed words into a string (text)\n","# and appends it to the corpus list.\n","# 6)Converts the text into a one-hot encoded representation\n","# based on a vocabulary size of 11000.\n","# 7)Pads the one-hot encoded representation to a fixed length\n","#  of 300 tokens.\n","# 8)After cleaning each sentence, the code attempts to predict\n","# the sentiment using a model (model.predict(sentence)) and print the predicted result along with the associated probability.\n","\n","# ----sentence_cleaning Function:\n","# .)This function takes in a sentence as input\n","# and performs various text preprocessing steps on it.\n","\n","# ---Text Preprocessing:\n","\n","# .)It uses regular expressions (re.sub) to remove any characters that are not alphabetic and replaces them with spaces.\n","# .)Converts the text to lowercase.\n","# .)Splits the sentence into individual words.\n","# .)Stemming and Stopword Removal:\n","\n","# .)It applies stemming to each word in the sentence using the Porter Stemmer (stemmer.stem(word)). Stemming reduces words to their root form.\n","# .)Removes stopwords (assuming stopwords is defined elsewhere in the code). Stopwords are common words (like \"and,\" \"the,\" \"is\") that often do not carry significant meaning in the context of analysis.\n","# -----One-Hot Encoding:\n","\n","# .)Joins the preprocessed words into a string (text) and\n","#  appends it to the corpus list.\n","# .)Converts the text into a one-hot encoded representation\n","# using a vocabulary size of 11000.\n","\n","# ------Padding Sequences:\n","\n","# .)Pads the one-hot encoded representation to a fixed\n","#  length of 300 tokens using pad_sequences\n","#   (assuming it's defined elsewhere in the code). This ensures that all sequences have the same length.\n","# -----Predicting Sentiment:\n","# .)The code then defines a list of example sentences\n","#  (sentences) and iterates through each sentence:\n","\n","# .)For each sentence, it cleans the sentence using the\n","# sentence_cleaning function.\n","\n","# .)It tries to make predictions on sentiment using a model\n","#  (model.predict(sentence)). However, the actual model definition\n","#   (model) and its associated components like lb\n","#    (assumed to be a label encoder) are not provided in the snippet.\n","\n","# .)It attempts to print the predicted sentiment and\n","# its associated probability (result and proba respectively).\n","\n","# .)Please note that for the code to fully work, it requires\n","#  additional parts such as the definition of the stopwords\n","#   list, the actual model for sentiment prediction (model),\n","#    the label encoder (lb), and potentially other functions\n","#     (one_hot, pad_sequences) to be defined and provided\n","#     elsewhere in the code."]},{"cell_type":"markdown","metadata":{"id":"5lzMbvOv_MqM"},"source":["#Predictive System"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bALHoy49hOWm"},"outputs":[],"source":["# Text cleaning function\n","def sentence_cleaning(sentence):\n","    stemmer = PorterStemmer()\n","    corpus = []\n","    text = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n","    text = text.lower()\n","    text = text.split()\n","    text = [stemmer.stem(word) for word in text if word not in stopwords]\n","    text = \" \".join(text)\n","    print(\"Text: \", text)\n","    corpus.append(text)\n","    print(\"Corpus\",corpus)\n","    # .)The blw one hot will give the intergers no from 0 to 11000\n","    # to thewords stored in corpus sentence by sentence inthe\n","    # form of array it will assign the unique word in that range\n","    one_hot_word = [one_hot(input_text=word, n=11000) for word in corpus]\n","    print(\"One Hot words\",one_hot_word)\n","    # .)In blw if any sent has 3 integers after one hot and other has 4\n","    # so there wil be differnce in size so the blw padding of\n","    # 300 will be prely applied to each sentence so the\n","    # input of size 300 will be supplied to neural netrowk\n","    pad = pad_sequences(sequences=one_hot_word, maxlen=300, padding='pre')\n","    print(\"Pad\",pad)\n","    return pad\n","\n","# load model and predict\n","sentences = [\n","            \"i feel strong and good overall\",\n","            \"im grabbing a minute to post i feel greedy wrong\",\n","            \"He was speechles when he found out he was accepted to this new job\",\n","            \"This is outrageous, how can you talk like that?\",\n","            \"I feel like im all alone in this world\",\n","            \"He is really sweet and caring\",\n","            \"You made me very crazy\",\n","            \"i am ever feeling nostalgic about the fireplace i will know that it is still on the property\",\n","            \"i am feeling grouchy\",\n","            \"He hates you\"\n","            ]\n","for sentence in sentences:\n","    print(sentence)\n","    sentence = sentence_cleaning(sentence)\n","    result = lb.inverse_transform(np.argmax(model.predict(sentence), axis=-1))[0]\n","    proba =  np.max(model.predict(sentence))\n","    print(f\"{result} : {proba}\\n\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1r6c1XIhhOZe"},"outputs":[],"source":["# Text cleaning function\n","def sentence_cleaning(sentence):\n","    stemmer = PorterStemmer()\n","    corpus = []\n","    text = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n","    text = text.lower()\n","    text = text.split()\n","    text = [stemmer.stem(word) for word in text if word not in stopwords]\n","    text = \" \".join(text)\n","    corpus.append(text)\n","    one_hot_word = [one_hot(input_text=word, n=11000) for word in corpus]\n","    pad = pad_sequences(sequences=one_hot_word, maxlen=300, padding='pre')\n","    return pad\n","\n","# load model and predict\n","sentences = [\n","            \"i feel strong and good overall\",\n","            \"im grabbing a minute to post i feel greedy wrong\",\n","            \"He was speechles when he found out he was accepted to this new job\",\n","            \"This is outrageous, how can you talk like that?\",\n","            \"I feel like im all alone in this world\",\n","            \"He is really sweet and caring\",\n","            \"You made me very crazy\",\n","            \"i am ever feeling nostalgic about the fireplace i will know that it is still on the property\",\n","            \"i am feeling grouchy\",\n","            \"He hates you\"\n","            ]\n","for sentence in sentences:\n","    print(sentence)\n","    sentence = sentence_cleaning(sentence)\n","    # result = model.predict(sentence)\n","    # print(f\"{result}\")\n","    result = lb.inverse_transform(np.argmax(model.predict(sentence), axis=-1))[0]\n","    proba =  np.max(model.predict(sentence))\n","    print(f\"{result} : {proba}\\n\\n\")"]},{"cell_type":"markdown","metadata":{"id":"IBBeRTt8SU_m"},"source":["#Save the model and files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1704083559537,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"iS59D9bAhOci","outputId":"e07396fc-e1f9-4f9e-c6aa-dffabdeec943"},"outputs":[],"source":["model.save('model1.h5')\n","\n","# Save the LabelEncoder\n","with open('lb1.pkl', 'wb') as f:\n","    pickle.dump(lb, f)\n","\n","# Save vocabulary size and max length\n","vocab_info = {'vocab_size': 11000, 'max_len': 300}\n","with open('vocab_info.pkl', 'wb') as f:\n","    pickle.dump(vocab_info, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1704082018670,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"BPk-okbnhOfO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1704082018670,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"beQLeioHhOiU"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"YJRTuW5jhOlP"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"lLzpUzRnhOoG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"r6qeHMAFhOrI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"5tHoW-T0hOuR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"Zb1ejjashOxf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"MBnh5mF8hNwA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"jo38gNaFhO0W"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"XCEgzCeQhO3s"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1704082018671,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"CEDjcjI7hO6X"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1704082018672,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"aGFaLorNhO9e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1704082018672,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"bxtIT-w2hO_8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1704082018672,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"Knny3KEUhPDF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1704082018672,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"rreKk9fthPF4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1704082018672,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"EaP0aBFIhPJC"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1704082018672,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"MD7ZQgfnhPL-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1704082018672,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"bgj54vW6hPSp"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704082018672,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"d3gi-3qEhPVy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1704082018673,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"bMidVELMhPYw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1704082018673,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"Wi9rha82hPbz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1704082018673,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"eO0n6zjchPex"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704082018673,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"DPXVeIeihPh6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704082018673,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"wvk2iMAZhPk5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704082018673,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"VwXkA2GohPoJ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082018673,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"PXl5agHzhPrL"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"l6JYbOxPhPuX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"R-R2HHHihPxl"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"p6Z9s9OUhP05"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"M1RspK94hP4L"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"iL5JfxnYhP7G"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"ly0cYNCxhP-U"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"9spnTphDhQD7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"vaMAp5MAhQHG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082019631,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"a5-HHWU3hQJ-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704082019632,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"sqR_KDPPhQM9"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704082019632,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"OqwZU3O1hQPs"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082019632,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"1UvgFOlRhQSi"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082019632,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"LR5MfXI7hQU7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082019632,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"uCHfehhUg4rv"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1704082019633,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"ggjrAKXLg4uf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082019633,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"KPufXUiog4xO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082019633,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"BLKbzvbqg40G"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082019633,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"C6s9WV5Cg424"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1704082019633,"user":{"displayName":"Muhammad Subhan Mujtaba","userId":"01997899486192861079"},"user_tz":-300},"id":"gcmuz2Hzg45l"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOvTBBUKiuBfv4ToU51gwPZ","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
